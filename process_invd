"""
This script, `process_inv.py`, is designed to handle inventory data files, primarily for the KBB MF project. 
Its primary goals are as follows:
1. Define and validate the base directory for accessing inventory data files.
2. Set up date range variables to specify the start and end periods for processing.
3. Implement functions to:
   - Process and stack inventory files for specific months and years.
   - Format data for consistent and streamlined reporting.
4. Organize files within a directory structure (e.g., `/clean/YYYY_MM/`) for efficient data retrieval and processing.

Key Features:
- Dynamic handling of inventory files based on specified year and month.
- Robust error handling to ensure smooth execution even if files or directories are missing.
- Integration with other scripts and workflows in the KBB MF project.

Prerequisites:
- Ensure that the base directory paths specified in `path_options` exist and contain the necessary inventory files.
- Verify that the `/clean/YYYY_MM/` directory structure is consistent with the expected format.

This script is integral to maintaining the accuracy and efficiency of inventory management workflows.
"""


import os
from pathlib import Path
import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import NamedStyle
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.styles import Font, PatternFill
from openpyxl import Workbook, load_workbook
import sys

# Define the base directory as before, now adding the /clean part
path_options = [
    '/Users/mauricioalouan/Dropbox/KBB MF/AAA/Balancetes/Fechamentos/data/',
    '/Users/simon/Library/CloudStorage/Dropbox/KBB MF/AAA/Balancetes/Fechamentos/data'
]
for path in path_options:
    if os.path.exists(path):
        base_dir = path
        break
else:
    print("None of the specified directories exist.")
    base_dir = None

# Subfolder with Tables
TABLES_SUBDIR = "Tables"
INPUT_SUBDIR = "clean"
OUTPUT_SUBDIR = "clean"
CLEAN_ROOT = os.path.join(base_dir, INPUT_SUBDIR) 
TABLES_DIR = os.path.join(base_dir, TABLES_SUBDIR)

# Function to process inventory files for a given month and year
def process_inventory_files(year, month):
    """Process and stack inventory files for a given year and month."""         
    try:
        # Format the month to always be two digits (e.g., 01, 02, ..., 12)
        month_str = f'{month:02d}'
        
        # The files for each month are inside the /clean/YYYY_MM/ folder
        clean_folder = os.path.join(base_dir, f'clean/{year}_{month_str}')

        # Define all file types with their corresponding 'Local' values
        file_configs = {
            f'B_Estoq_{year}_{month_str}_clean.xlsx': 'Bling',
            f'T_EstTrans_{year}_{month_str}_clean.xlsx': 'Transito',
            f'O_Estoq_{year}_{month_str}_clean.xlsx': None,  # Special case with its own column
            f'B_EFullAj_{year}_{month_str}_clean.xlsx': 'Ajuste',
            f'B_EFullAm_{year}_{month_str}_clean.xlsx': 'Amazon Full',
            f'B_EFullML_{year}_{month_str}_clean.xlsx': 'ML Full',
            f'B_EFullMg_{year}_{month_str}_clean.xlsx': 'Magalu Full',
            f'B_EFullSh_{year}_{month_str}_clean.xlsx': 'Shopee Full',
            f'B_EFullPl_{year}_{month_str}_clean.xlsx': 'Planeta',
            f'B_EFullMe_{year}_{month_str}_clean.xlsx': 'Mega'
        }

        combined_dfs = []

        # Process each file
        for file_name, local_value in file_configs.items():
            file_path = os.path.join(clean_folder, file_name)
            try:
                if os.path.exists(file_path):
                    if 'O_Estoq' in file_name:
                        # Special handling for O_Estoq
                        df = pd.read_excel(file_path, usecols=['Código do Produto', 'Quantidade', 'Local de Estoque (Código)'])
                        df.rename(columns={
                            'Código do Produto': 'CODPF',
                            'Quantidade': 'Qt',
                            'Local de Estoque (Código)': 'Local'
                        }, inplace=True)
                    elif 'T_EstTrans' in file_name:
                        # Special handling for T_EstTrans
                        df = pd.read_excel(file_path, usecols=['CodProd', 'Qt'])
                        df.rename(columns={'CodProd': 'CODPF', 'Qt': 'Qt'}, inplace=True)
                        df['Local'] = 'Transito'
                    else:
                        # General handling
                        df = pd.read_excel(file_path, usecols=['Código', 'Quantidade'])
                        df.rename(columns={'Código': 'CODPF', 'Quantidade': 'Qt'}, inplace=True)
                        if local_value:
                            df['Local'] = local_value
                    combined_dfs.append(df)
                else:
                    print(f"File not found: {file_name}. Skipping this file.")
            except Exception as e:
                print(f"Error processing inventory files for {year}-{month_str}, file prefix: {file_name}: {e}")
                continue  # Skip this file and proceed with the next

        # Combine all dataframes
        if combined_dfs:
            combined_df = pd.concat(combined_dfs, ignore_index=True)
        else:
            print(f"No files found for {year}-{month_str}. Returning an empty DataFrame.")
            combined_df = pd.DataFrame(columns=['CODPF', 'Qt', 'Local'])

        combined_df["CODPF"] = combined_df["CODPF"].astype(str).str.strip().str.upper()
        print(f"Combined inventory for {year}-{month_str}: ---- AAA ---")
        print(combined_df.head())
        print(combined_df["Local"].unique().tolist())

        return combined_df

    except Exception as e:
        print(f"Error processing inventory files for {year}-{month_str}: {e}")
        return None

def load_prodf(tables_dir: Path) -> pd.DataFrame:
    path = tables_dir / "T_Prodf.xlsx"
    if not path.exists():
        raise FileNotFoundError(f"Arquivo Prodf.xlsx não encontrado em {tables_dir}")
    df = pd.read_excel(path)
    df["CODPF"] = df["CodPF"].astype(str).str.strip().str.upper()
    df["CODPP"] = df["CodPP"].astype(str).str.strip().str.upper()
    return df[["CODPF", "CODPP"]]

def resolve_tables_dir(year: int, month: int) -> Path:
    p = Path(os.path.join(TABLES_DIR))
    if not p.exists():
        raise FileNotFoundError(f"Pasta das Tabelas não encontrada: {p}")
    return p

def create_pivot_sheet_pf(wb, df, group_col, sheet_name, year, month):
    number_format = '#,##0.00'

    print("Columns available in df:", df.columns.tolist())

    pivot_table = df.pivot_table(
        index='CODPF',
        columns='Local',
        values='Qt',
        aggfunc='sum',
        fill_value=0
    )

    pivot_table['Qt_SS'] = pivot_table.sum(axis=1)
    pCT_F = df.groupby('CODPF')['CT_F'].sum()
    pivot_table['CT_F'] = pCT_F
    pivot_table['CU_F'] = pivot_table['CT_F'] / pivot_table['Qt_SS']
    pivot_table['AnoMes'] = (year % 100) * 100 + month

    pivot_table = pivot_table.reset_index()

    # Cria aba se não existir
    if sheet_name not in wb.sheetnames:
        wb.create_sheet(title=sheet_name)
    ws = wb[sheet_name]

    # Headers
    for col_idx, header in enumerate(pivot_table.columns, start=1):
        ws.cell(row=1, column=col_idx, value=header)

    # Dados
    for r_idx, row in enumerate(pivot_table.itertuples(index=False), start=2):
        for c_idx, value in enumerate(row, start=1):
            ws.cell(row=r_idx, column=c_idx, value=value)

    # Linha de totais
    totals_row_idx = len(pivot_table) + 2
    ws.cell(row=totals_row_idx, column=1, value="Grand Total").font = Font(bold=True)
    for col_idx, col_name in enumerate(pivot_table.columns[1:], start=2):
        total_value = pivot_table[col_name].sum()
        cell = ws.cell(row=totals_row_idx, column=col_idx, value=total_value)
        cell.font = Font(bold=True)
        if col_name in ['CT_F', 'CU_F']:
            cell.number_format = number_format

    # Estilo especial para colunas de totais
    gray_fill = PatternFill(start_color="D3D3D3", end_color="D3D3D3", fill_type="solid")
    for col_name in ['Qt_SS', 'CT_F', 'CU_F']:
        if col_name in pivot_table.columns:
            col_idx = pivot_table.columns.get_loc(col_name) + 1
            for row in range(2, totals_row_idx + 1):
                cell = ws.cell(row=row, column=col_idx)
                cell.font = Font(bold=True)
                cell.fill = gray_fill
                cell.number_format = number_format

    ws.auto_filter.ref = ws.dimensions

from openpyxl.styles import Font, PatternFill

from openpyxl.styles import Font, PatternFill

def create_pivot_sheet_pp(wb, df, group_col, sheet_name, year, month):
    number_format = '#,##0.00'

    print("Columns available in df:", df.columns.tolist())

    # --- Pivot base quantities ---
    pivot_table = df.pivot_table(
        index='CODPP',
        columns='Local',
        values='Qt',
        aggfunc='sum',
        fill_value=0
    )

    # --- Derived totals ---
    pivot_table['Qt_SS'] = pivot_table.sum(axis=1)

    # --- Aggregate costs ---
    pCT_F = df.groupby('CODPP')['CT_F'].sum()
    pivot_table['CT_F'] = pCT_F
    pivot_table['CU_F'] = pivot_table['CT_F'] / pivot_table['Qt_SS']

    pivot_table['AnoMes'] = (year % 100) * 100 + month

    # --- Add entry and sales info (same formulas as your original) ---
    pQt_E = df.groupby('CODPP')['Qt_E'].mean()
    pCU_E = df.groupby('CODPP')['CU_E'].mean()
    pivot_table['Qt_E'] = pQt_E
    pivot_table['CU_E'] = pCU_E.round(2)
    pivot_table['CT_E'] = (pivot_table['CU_E'] * pivot_table['Qt_E']).round(2)
    pCU_S = df.groupby('CODPP')['CU_S'].mean()
    pivot_table['CU_S'] = pCU_S.round(2)

    pivot_table = pivot_table.reset_index()

    # --- Create or reuse sheet ---
    if sheet_name not in wb.sheetnames:
        wb.create_sheet(title=sheet_name)
    ws = wb[sheet_name]

    # --- Write headers ---
    for col_idx, header in enumerate(pivot_table.columns, start=1):
        ws.cell(row=1, column=col_idx, value=header).font = Font(bold=True)

    # --- Write data ---
    for r_idx, row in enumerate(pivot_table.itertuples(index=False), start=2):
        for c_idx, value in enumerate(row, start=1):
            ws.cell(row=r_idx, column=c_idx, value=value)

    # --- Totals row ---
    totals_row_idx = len(pivot_table) + 2
    ws.cell(row=totals_row_idx, column=1, value="Grand Total").font = Font(bold=True)
    for col_idx, col_name in enumerate(pivot_table.columns[1:], start=2):
        total_value = pivot_table[col_name].sum()
        cell = ws.cell(row=totals_row_idx, column=col_idx, value=total_value)
        cell.font = Font(bold=True)
        if col_name in ['CT_F', 'CU_F', 'Qt_E', 'CU_E', 'CT_E', 'CU_S']:
            cell.number_format = number_format

    # --- Column styling ---
    gray_fill = PatternFill(start_color="D3D3D3", end_color="D3D3D3", fill_type="solid")
    blue_fill = PatternFill(start_color="BDD7EE", end_color="BDD7EE", fill_type="solid")

    gray_cols = ['Qt_SS', 'CT_F', 'CU_F']
    blue_cols = ['Qt_E', 'CU_E', 'CT_E', 'CU_S']

    for col_name in gray_cols + blue_cols:
        if col_name in pivot_table.columns:
            col_idx = pivot_table.columns.get_loc(col_name) + 1
            for row in range(2, totals_row_idx + 1):
                cell = ws.cell(row=row, column=col_idx)
                cell.font = Font(bold=True)
                cell.fill = gray_fill if col_name in gray_cols else blue_fill
                cell.number_format = number_format

    ws.auto_filter.ref = ws.dimensions
    print(f"✅ Created pivot sheet '{sheet_name}' (formatting only; logic unchanged).")

# Function to lookup CU values and additional columns
# Function to lookup CU values and additional columns
def lookup_cu_values(inventory_df, anomes):
    print("\n[lookup_cu_values] START")
    print(f"[lookup_cu_values] cutoff YYMM = {anomes}")

    try:
        entradas_df = pd.read_excel(
            os.path.join(base_dir, 'Tables', 'T_Entradas.xlsx'),
            dtype={'Pai': str}
        )
        entradas_df["Pai"] = entradas_df["Pai"].astype(str).str.strip().str.upper()

        # ➤ Converte a data da última entrada
        entradas_df = entradas_df[entradas_df['AnoMes'] <= anomes]
        #print("\n[entradas_df] ")
        #pd.set_option('display.max_columns', None)
        #print(entradas_df)
        #print(entradas_df.columns.tolist())

        last_cu_pai = (
            entradas_df[entradas_df['Pai'].notna() & (entradas_df['Pai'] != '')]
            .sort_values(['Pai', 'AnoMes'])
            .drop_duplicates(subset='Pai', keep='last')[
                ['Pai', 'Inv', 'AnoMes', 'CU_E', 'PGE', 'CU_I', 'CU_S', 'CU_F', 'Qt_E']
            ]
        )
        print("\n[last_cu_pai] --- BBB")
        pd.set_option('display.max_columns', None)
        print(last_cu_pai)
        print(last_cu_pai.columns.tolist())
        print(last_cu_pai[last_cu_pai["Pai"] == "30100"])

        # Step 3: merge with last known parent cost table
        inventory_df = inventory_df.merge(
            last_cu_pai,
            left_on="CODPP",
            right_on="Pai",
            how="left"
        )

        #inventory_df['CT_E'] = inventory_df['CU_E'] * inventory_df['Qt']
        #inventory_df['CT_I'] = inventory_df['CU_I'] * inventory_df['Qt']
        inventory_df['CT_F'] = inventory_df['CU_F'] * inventory_df['Qt']

        print("\n[inventory_df] --- CCC")
        pd.set_option('display.max_columns', None)
        print(inventory_df)
        print(inventory_df.columns.tolist())
        print(inventory_df[inventory_df["Pai"] == "30100"])

        return inventory_df

    except Exception as e:
        print(f"Error looking up CU values: {e}")
        return None


# Main function to handle the process for all months within the date range
def main(year, month):
    tables_dir = resolve_tables_dir(year, month)
    prodf    = load_prodf(tables_dir)                     # CODPP, CODPF (estrutura)
    print(f"\nprodf: AAABBB")
    print(prodf.head())

    # Loop through each year and month in the specified range
    print(f"Processing data for year {year}, month {month:02d}")

    # Step 1: Process and stack inventory data for the given year and month
    inventory_df = process_inventory_files(year, month)
    #print(f"\ninventory_df: AAA----")
    #print(inventory_df)

    inventory_df = inventory_df.merge(
            prodf[["CODPF", "CODPP"]],
            on="CODPF",
            how="left",
            validate="m:1"
        )
    # 🩵 If no parent found, use same code as self
    inventory_df["CODPP"] = inventory_df["CODPP"].fillna(inventory_df["CODPF"])

    anomes = (year - 2000) * 100 + month
    print(f"\ninventory_df: AAA --- {anomes}")
    print(inventory_df)


    final_df = lookup_cu_values(inventory_df, anomes)
    print("\nfinal_df:")
    print(final_df.head())

    # Add AnoMes
    final_df['UltEntr'] = final_df['AnoMes']
    final_df = final_df.drop(["Pai"], axis=1)
    final_df['AnoMes'] = (year % 100) * 100 + month
    # Step 3: Save the resulting dataframe to a new Excel file
    output_filepath = os.path.join(base_dir, 'clean',f'{year}_{month:02d}', f'R_Estoq_fdm_{year}_{month:02d}.xlsx')
    final_df.to_excel(output_filepath, index=False, sheet_name='Data')
    print(f"Saved combined inventory data for {year}-{month:02d} to {output_filepath}")
    add_pivot_by_filho(output_filepath, final_df, year,month)
    add_pivot_by_pai(output_filepath, final_df, year, month)
    print(f"Added Formating and Pivots for {year}-{month:02d} to {output_filepath}")

# Format and add pivot tables using openpyxl
def add_pivot_by_filho(output_filepath, df, year, month):
    wb = load_workbook(output_filepath)

    # Formatar a aba 'Data'
    ws = wb['Data']
    number_format = '#,##0.00'
    columns_to_format = ['CU_E', 'PGE', 'CU_I', 'CU_S', 'CU_F', 'CT_F']
    for col in columns_to_format:
        if col in df.columns:
            col_idx = df.columns.get_loc(col) + 1
            for row in range(2, len(df) + 2):
                cell = ws.cell(row=row, column=col_idx)
                cell.number_format = number_format
    ws.auto_filter.ref = ws.dimensions

    # Criar aba PT01 (por SKU)
    create_pivot_sheet_pf(wb, df, group_col='CODPF', sheet_name='PT01', year=year, month=month)
    wb.save(output_filepath)

def add_pivot_by_pai(output_filepath, df, year, month):
    wb = load_workbook(output_filepath)
    create_pivot_sheet_pp(wb, df, group_col='CODPP', sheet_name='PT_pp', year=year, month=month)
    wb.save(output_filepath)


if __name__ == "__main__":
    import argparse
    from datetime import datetime

    ap = argparse.ArgumentParser(description="Inventory reconciliation for a given year/month.")
    ap.add_argument("--year", "-y", type=int, help="Year, e.g. 2025")
    ap.add_argument("--month", "-m", type=int, help="Month, 1-12")
    args = ap.parse_args()

    # If missing, ask interactively
    if args.year is None or args.month is None:
        now = datetime.now()
        print("Year and/or month not provided.")
        year = int(input(f"Enter year (default {now.year}): ") or now.year)
        month = int(input(f"Enter month [1-12] (default {now.month -1}): ") or (now.month -1))
    else:
        year, month = args.year, args.month

    main(year, month)
